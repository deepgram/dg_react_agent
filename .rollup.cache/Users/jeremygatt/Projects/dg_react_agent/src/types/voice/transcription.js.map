{"version":3,"file":"transcription.js","sourceRoot":"","sources":["transcription.ts"],"names":[],"mappings":"AAAA;;GAEG","sourcesContent":["/**\n * Types related to Deepgram's transcription API\n */\n\n/**\n * Configuration for the Deepgram transcription API\n * Based on Deepgram /v1/listen query parameters\n */\nexport interface TranscriptionOptions {\n  /**\n   * Transcription model to use\n   * e.g., \"nova-2\"\n   */\n  model?: string;\n\n  /**\n   * Language to transcribe\n   * e.g., \"en-US\"\n   */\n  language?: string;\n\n  /**\n   * Enable speaker identification\n   */\n  diarize?: boolean;\n\n  /**\n   * Enable smart formatting of numbers, dates, etc.\n   */\n  smart_format?: boolean;\n\n  /**\n   * Add punctuation to the transcript\n   */\n  punctuate?: boolean;\n\n  /**\n   * Enable automatic endpoint detection\n   * Can be boolean or milliseconds of silence\n   */\n  endpointing?: boolean | number;\n\n  /**\n   * Return interim (non-final) results\n   */\n  interim_results?: boolean;\n\n  /**\n   * Enable voice activity detection events\n   */\n  vad_events?: boolean;\n\n  /**\n   * Keywords to detect in the audio.\n   * @see https://developers.deepgram.com/docs/keywords\n   */\n  keywords?: string[];\n\n  /**\n   * Keyterms to boost recognition for (Nova-3 English only).\n   * Each string in the array will be sent as a separate 'keyterm' parameter.\n   * Phrases with spaces are handled correctly.\n   * @see https://developers.deepgram.com/docs/keyterm\n   */\n  keyterm?: string[];\n\n  /**\n   * Any other parameters supported by Deepgram API\n   */\n  [key: string]: any;\n}\n\n/**\n * Word object in a transcript\n */\nexport interface TranscriptWord {\n  /**\n   * The transcribed word\n   */\n  word: string;\n\n  /**\n   * Start time in seconds\n   */\n  start: number;\n\n  /**\n   * End time in seconds\n   */\n  end: number;\n\n  /**\n   * Confidence score (0-1)\n   */\n  confidence: number;\n\n  /**\n   * Speaker ID (if diarization is enabled)\n   */\n  speaker?: number;\n}\n\n/**\n * Alternative transcript\n */\nexport interface TranscriptAlternative {\n  /**\n   * The transcript text\n   */\n  transcript: string;\n\n  /**\n   * Confidence score (0-1)\n   */\n  confidence: number;\n\n  /**\n   * Words with timing information\n   */\n  words: TranscriptWord[];\n}\n\n/**\n * Transcript response from Deepgram\n */\nexport interface TranscriptResponse {\n  /**\n   * Indicates this is a transcript message\n   */\n  type: 'transcript';\n\n  /**\n   * Audio channel index\n   */\n  channel: number;\n\n  /**\n   * Whether this is a final result\n   */\n  is_final: boolean;\n\n  /**\n   * Whether speech has ended\n   */\n  speech_final: boolean;\n\n  /**\n   * Channel indexes for multi-channel audio\n   */\n  channel_index: number[];\n\n  /**\n   * Start time of this segment in seconds\n   */\n  start: number;\n\n  /**\n   * Duration of this segment in seconds\n   */\n  duration: number;\n\n  /**\n   * Alternative transcriptions, ordered by confidence\n   */\n  alternatives: TranscriptAlternative[];\n\n  /**\n   * Additional metadata\n   */\n  metadata?: any;\n}\n\n/**\n * Voice activity detection event\n */\nexport interface VADEvent {\n  /**\n   * Indicates this is a VAD event\n   */\n  type: 'vad';\n\n  /**\n   * Start time in seconds\n   */\n  start: number;\n\n  /**\n   * End time in seconds\n   */\n  end: number;\n\n  /**\n   * Whether speech is present\n   */\n  speech_detected: boolean;\n}\n\n/**\n * Union type for all transcription messages\n */\nexport type TranscriptionMessage = TranscriptResponse | VADEvent;\n"]}